{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_21831/346106162.py:21: FutureWarning: The behavior of DataFrame.idxmin with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  air_quality['min_hour'] = air_quality[columns].idxmin(axis=1).str.extract(r'(\\d+)')\n",
      "/var/folders/3s/sgsxmx5n0nv1mqxxx0w71rn40000gn/T/ipykernel_21831/346106162.py:22: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  air_quality['max_hour'] = air_quality[columns].idxmax(axis=1).str.extract(r'(\\d+)')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "air_quality = pd.read_csv('data/airquality/air_quality.csv')\n",
    "\n",
    "air_quality['DATA'] = pd.to_datetime(pd.to_datetime(air_quality['DATA'], format = '%d/%m/%Y').dt.date)\n",
    "air_quality = air_quality.loc[air_quality.DATA.dt.year<2019]\n",
    "\n",
    "# Convert the specified columns to numeric\n",
    "columns = ['01h', '02h', '03h', '04h', '05h', '06h', '07h', '08h', '09h', '10h',\\\n",
    "            '11h', '12h', '13h', '14h', '15h', '16h', '17h', '18h', '19h', '20h',\\\n",
    "            '21h', '22h', '23h', '24h']\n",
    "air_quality[columns] = air_quality[columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Create new columns min, max, mean\n",
    "air_quality['min'] = air_quality[columns].min(axis=1)\n",
    "air_quality['max'] = air_quality[columns].max(axis=1)\n",
    "air_quality['mean'] = air_quality[columns].mean(axis=1)\n",
    "\n",
    "# Extracting the hour of the column with the minimum value\n",
    "air_quality['min_hour'] = air_quality[columns].idxmin(axis=1).str.extract(r'(\\d+)')\n",
    "air_quality['max_hour'] = air_quality[columns].idxmax(axis=1).str.extract(r'(\\d+)')\n",
    "air_quality['min_hour'] = pd.to_numeric(air_quality.min_hour)\n",
    "air_quality['max_hour'] = pd.to_numeric(air_quality.max_hour)\n",
    "\n",
    "######################################\n",
    "######### AIR QUALITY LEGEND #########\n",
    "######################################\n",
    "air_quality_legend = air_quality[['NOM ESTACIO','CONTAMINANT','LATITUD', 'LONGITUD', 'LIMADM COMARCA']].drop_duplicates(subset = ['NOM ESTACIO','CONTAMINANT']).reset_index(drop = True)\n",
    "air_quality_legend.columns = ['codi_estacio', 'contaminant', 'latitud', 'longitud', 'com_code']\n",
    "air_quality_legend['com_code'] = air_quality_legend['com_code'].astype(str).str.zfill(2)\n",
    "pc_muni_com_at_codes = pd.read_csv(\"data/geo_codes/pc_muni_com_at_codes.csv\")\n",
    "com_at_codes_legend = pc_muni_com_at_codes[['com_code','at_code']].drop_duplicates().reset_index(drop=True)\n",
    "com_at_codes_legend[\"com_code\"] = com_at_codes_legend[\"com_code\"].astype(str).str.zfill(2)\n",
    "com_at_codes_legend = com_at_codes_legend.sort_values('com_code').drop_duplicates(subset = 'com_code')\n",
    "air_quality_legend = air_quality_legend.merge(com_at_codes_legend, on = 'com_code', how = 'inner')\n",
    "\n",
    "\n",
    "######################################\n",
    "######### AIR QUALITY TABLE ##########\n",
    "######################################\n",
    "dates = pd.date_range(start='2010-01-01', end='2018-12-31', freq='D')\n",
    "\n",
    "# Create a DataFrame with all combinations of 'codi_estacio' and 'contaminant' for each date\n",
    "date_combinations = pd.DataFrame(list(product(dates, air_quality_legend['codi_estacio'].unique(), air_quality_legend['contaminant'].unique())), columns=['date', 'codi_estacio', 'contaminant'])\n",
    "date_combinations = pd.merge(date_combinations, air_quality_legend[['codi_estacio', 'contaminant']], on=['codi_estacio', 'contaminant'], how='inner')\n",
    "\n",
    "# Rename columns in air_quality\n",
    "air_quality.rename(columns={'NOM ESTACIO': 'codi_estacio',\\\n",
    "                            'CONTAMINANT': 'contaminant',\\\n",
    "                            'DATA': 'date'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(date_combinations, air_quality, how='left', on=['date', 'codi_estacio', 'contaminant'])\n",
    "merged_df = merged_df[['codi_estacio','contaminant','date','min', 'max', 'mean','min_hour','max_hour'] + columns]\n",
    "air_quality_at = air_quality.merge(air_quality_legend[['codi_estacio','at_code']].drop_duplicates(), on = 'codi_estacio', how = 'left')\n",
    "air_quality_clean = air_quality_at[['date', 'contaminant','min', 'max', 'mean', 'min_hour', 'max_hour', 'at_code']]\n",
    "\n",
    "\n",
    "######################################\n",
    "######### AIR QUALITY AGG ############\n",
    "######################################\n",
    "air_quality_clean = air_quality_clean.groupby(['date', 'contaminant', 'at_code']).mean().reset_index()\n",
    "air_quality_clean['na'] = air_quality_clean.isna().sum(axis=1)\n",
    "air_quality_clean = air_quality_clean.loc[air_quality_clean.na<=0].reset_index(drop = True)\n",
    "air_quality_clean['min_hour'] = air_quality_clean['min_hour'].round().astype(int)\n",
    "air_quality_clean['max_hour'] = air_quality_clean['max_hour'].round().astype(int)\n",
    "air_quality_clean = air_quality_clean.sort_values(['at_code','date']).reset_index(drop = True).drop(columns = 'na')\n",
    "\n",
    "air_quality_clean.to_csv('data/airquality/air_quality_clean.csv', index = False)\n",
    "\n",
    "######################################\n",
    "######### AIR QUALITY PIVOT ##########\n",
    "######################################\n",
    "# Create pivot table\n",
    "pivot_table = air_quality_clean.pivot_table(index=['date', 'at_code'], columns='contaminant', values=['min', 'max', 'mean', 'min_hour', 'max_hour'])\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "pivot_table.columns = ['_'.join(col) for col in pivot_table.columns.values]\n",
    "\n",
    "# Reset index\n",
    "pivot_table = pivot_table.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################\n",
    "######### AIR QUALITY MERGE ##########\n",
    "######################################\n",
    "environment = pd.read_csv('modelling_data/temp_hum_clean.csv')\n",
    "environment['date'] = pd.to_datetime(environment['date'])\n",
    "environment = environment.merge(pivot_table, on = ['at_code','date'], how = 'left')\n",
    "environment.to_csv('modelling_data/environment.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
